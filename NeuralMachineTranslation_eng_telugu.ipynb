{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NeuralMachineTranslation_eng_telugu.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "TphUnHWf_52Y"
      },
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import numpy as np\n",
        "import nltk.translate.bleu_score as bleu\n",
        "import random\n",
        "import string\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os\n",
        "import time"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "X4Opm0xU_7OX",
        "outputId": "73af5015-e65b-4b21-dfdf-4b4ec5f6c5fb"
      },
      "source": [
        "eng_tel=pd.read_csv('eng_tel.csv')\n",
        "eng_tel.head()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>English</th>\n",
              "      <th>Telugu</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>politicians do not have permission to do what ...</td>\n",
              "      <td>రాజకీయ నాయకులకు చేయవలసినది చేయడానికి అనుమతి లేదు.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I'd like to tell you about one such child,</td>\n",
              "      <td>అలాంటి ఒక పిల్లల గురించి నేను మీకు చెప్పాలనుకు...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>This percentage is even greater than the perce...</td>\n",
              "      <td>ఈ శాతం భారతదేశంలో ఉన్న శాతం కంటే ఎక్కువ.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>what we really mean is that they're bad at not...</td>\n",
              "      <td>మేము నిజంగా అర్థం ఏమిటంటే వారు శ్రద్ధ చూపకపోవడ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>.The ending portion of these Vedas is called U...</td>\n",
              "      <td>.ఈ వేదాల ముగింపు భాగాన్ని ఉపనిషత్తు అంటారు.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             English                                             Telugu\n",
              "0  politicians do not have permission to do what ...  రాజకీయ నాయకులకు చేయవలసినది చేయడానికి అనుమతి లేదు.\n",
              "1         I'd like to tell you about one such child,  అలాంటి ఒక పిల్లల గురించి నేను మీకు చెప్పాలనుకు...\n",
              "2  This percentage is even greater than the perce...           ఈ శాతం భారతదేశంలో ఉన్న శాతం కంటే ఎక్కువ.\n",
              "3  what we really mean is that they're bad at not...  మేము నిజంగా అర్థం ఏమిటంటే వారు శ్రద్ధ చూపకపోవడ...\n",
              "4  .The ending portion of these Vedas is called U...        .ఈ వేదాల ముగింపు భాగాన్ని ఉపనిషత్తు అంటారు."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2yQUqA6g_8lh",
        "outputId": "d97ded32-fb7d-4422-c375-64427b1b34e7"
      },
      "source": [
        "eng_tel.dropna(inplace=True)\n",
        "eng_tel.shape"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5615, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zlhv9yF1AIBf"
      },
      "source": [
        "exclude = set(string.punctuation) # Set of all special characters\n",
        "remove_digits = str.maketrans('', '', string.digits) # Set of all digits"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qeQ2I1iDAJ5o"
      },
      "source": [
        "def preprocess(text):\n",
        "    '''Function to preprocess English sentence'''\n",
        "    text = text.lower() # lower casing\n",
        "    text = re.sub(\"'\", '', text) # remove the quotation marks if any\n",
        "    text = ''.join(ch for ch in text if ch not in exclude)\n",
        "    text = text.translate(remove_digits) # remove the digits\n",
        "    text = text.strip()\n",
        "    text = re.sub(\" +\", \" \", text) # remove extra spaces\n",
        "    text = '<start> ' + text + ' <end>'\n",
        "    return text"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aQcdfXMDALjr"
      },
      "source": [
        "def preprocess_tel(text):\n",
        "    '''Function to preprocess Telugu sentence'''\n",
        "    text = re.sub(\"'\", '', text) # remove the quotation marks if any\n",
        "    text = ''.join(ch for ch in text if ch not in exclude)\n",
        "    text = text.strip()\n",
        "    text = re.sub(\" +\", \" \", text) # remove extra spaces\n",
        "    text = '<start> ' + text + ' <end>'\n",
        "    return text"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "uYYoa6mfAc0Q",
        "outputId": "c12ae41c-44c7-453b-8d93-8b160d2b751b"
      },
      "source": [
        "eng_tel['English'] = eng_tel['English'].apply(preprocess)\n",
        "eng_tel['Telugu'] = eng_tel['Telugu'].apply(preprocess_tel)\n",
        "\n",
        "\n",
        "eng_tel.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>English</th>\n",
              "      <th>Telugu</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>&lt;start&gt; politicians do not have permission to ...</td>\n",
              "      <td>&lt;start&gt; రాజకీయ నాయకులకు చేయవలసినది చేయడానికి అ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>&lt;start&gt; id like to tell you about one such chi...</td>\n",
              "      <td>&lt;start&gt; అలాంటి ఒక పిల్లల గురించి నేను మీకు చెప...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>&lt;start&gt; this percentage is even greater than t...</td>\n",
              "      <td>&lt;start&gt; ఈ శాతం భారతదేశంలో ఉన్న శాతం కంటే ఎక్కు...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>&lt;start&gt; what we really mean is that theyre bad...</td>\n",
              "      <td>&lt;start&gt; మేము నిజంగా అర్థం ఏమిటంటే వారు శ్రద్ధ ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>&lt;start&gt; the ending portion of these vedas is c...</td>\n",
              "      <td>&lt;start&gt; ఈ వేదాల ముగింపు భాగాన్ని ఉపనిషత్తు అంట...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             English                                             Telugu\n",
              "0  <start> politicians do not have permission to ...  <start> రాజకీయ నాయకులకు చేయవలసినది చేయడానికి అ...\n",
              "1  <start> id like to tell you about one such chi...  <start> అలాంటి ఒక పిల్లల గురించి నేను మీకు చెప...\n",
              "2  <start> this percentage is even greater than t...  <start> ఈ శాతం భారతదేశంలో ఉన్న శాతం కంటే ఎక్కు...\n",
              "3  <start> what we really mean is that theyre bad...  <start> మేము నిజంగా అర్థం ఏమిటంటే వారు శ్రద్ధ ...\n",
              "4  <start> the ending portion of these vedas is c...  <start> ఈ వేదాల ముగింపు భాగాన్ని ఉపనిషత్తు అంట..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1zNS9JknEWfa"
      },
      "source": [
        "def tokenize(lang):\n",
        "\n",
        "  lang_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='')\n",
        "  lang_tokenizer.fit_on_texts(lang)\n",
        "\n",
        "  tensor = lang_tokenizer.texts_to_sequences(lang)\n",
        "\n",
        "  tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor,padding='post',maxlen=20,dtype='int32')\n",
        "\n",
        "  return tensor, lang_tokenizer"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4jQkH882Fs9x"
      },
      "source": [
        "def load_dataset():\n",
        "\n",
        "  input_tensor, inp_lang_tokenizer = tokenize(eng_tel['English'].values)\n",
        "  target_tensor, targ_lang_tokenizer = tokenize(eng_tel['Telugu'].values)\n",
        "\n",
        "  return input_tensor, target_tensor, inp_lang_tokenizer, targ_lang_tokenizer"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4-Wg24AOFO9s"
      },
      "source": [
        "input_tensor, target_tensor, inp_lang, targ_lang = load_dataset()"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lUvO_uSiGCLC"
      },
      "source": [
        "max_length_targ, max_length_inp = target_tensor.shape[1], input_tensor.shape[1]"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7G9J9aanGEnY",
        "outputId": "35d94531-2ba2-4f9d-fc6a-24998bf167b8"
      },
      "source": [
        "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.15)\n",
        "\n",
        "print(len(input_tensor_train), len(target_tensor_train), len(input_tensor_val), len(target_tensor_val))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4772 4772 843 843\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r9oyMQjLGZ4x"
      },
      "source": [
        "BUFFER_SIZE = len(input_tensor_train)\n",
        "BATCH_SIZE = 16\n",
        "N_BATCH = BUFFER_SIZE//BATCH_SIZE\n",
        "embedding_dim = 128\n",
        "units = 1024\n",
        "steps_per_epoch = len(input_tensor_train)//BATCH_SIZE\n",
        "\n",
        "vocab_inp_size =len(inp_lang.word_index.keys())\n",
        "vocab_tar_size =len(targ_lang.word_index.keys())\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train)).shuffle(BUFFER_SIZE)\n",
        "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AKD-3jidQtND"
      },
      "source": [
        "embeddings_index = dict()\n",
        "f = open('glove.6B.300d.txt')\n",
        "for line in f:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    coefs = np.asarray(values[1:], dtype='float32')\n",
        "    embeddings_index[word] = coefs\n",
        "f.close()\n",
        "\n",
        "embedding_matrix = np.zeros((vocab_inp_size+1, 300))\n",
        "for word, i in inp_lang.word_index.items():\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix[i] = embedding_vector"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I_-Bj6ENHE4I"
      },
      "source": [
        "class Encoder(tf.keras.Model):\n",
        "    def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.batch_sz = batch_sz\n",
        "        self.enc_units = enc_units\n",
        "        self.embedding = tf.keras.layers.Embedding(input_dim=vocab_size, output_dim=embedding_dim, name=\"embedding_layer_encoder\",trainable=False)\n",
        "        self.gru = tf.keras.layers.GRU(units, return_sequences=True, return_state=True, recurrent_activation='sigmoid', recurrent_initializer='glorot_uniform')\n",
        "        \n",
        "    def call(self, x, hidden):\n",
        "        x = self.embedding(x)\n",
        "        output, state = self.gru(x, initial_state = hidden)\n",
        "        return output, state\n",
        "    \n",
        "    def initialize_hidden_state(self):\n",
        "        return tf.zeros((self.batch_sz, self.enc_units))"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "afDryQ94HdKt"
      },
      "source": [
        "class Decoder(tf.keras.Model):\n",
        "    def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.batch_sz = batch_sz\n",
        "        self.dec_units = dec_units\n",
        "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "        self.gru = tf.keras.layers.GRU(units, return_sequences=True, return_state=True, recurrent_activation='sigmoid', recurrent_initializer='glorot_uniform')\n",
        "        self.fc = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "                # used for attention\n",
        "        self.W1 = tf.keras.layers.Dense(self.dec_units)\n",
        "        self.W2 = tf.keras.layers.Dense(self.dec_units)\n",
        "        self.V = tf.keras.layers.Dense(1)\n",
        "\n",
        "    def call(self, x, hidden, enc_output):\n",
        "\n",
        "        hidden_with_time_axis = tf.expand_dims(hidden, 1)\n",
        "        \n",
        "        score = self.V(tf.nn.tanh(self.W1(enc_output) + self.W2(hidden_with_time_axis)))\n",
        "        \n",
        "        attention_weights = tf.nn.softmax(score, axis=1)\n",
        "        \n",
        "        context_vector = attention_weights * enc_output\n",
        "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
        "        \n",
        "        x = self.embedding(x)\n",
        "        \n",
        "        x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
        "        \n",
        "        output, state = self.gru(x)\n",
        "        \n",
        "        output = tf.reshape(output, (-1, output.shape[2]))\n",
        "        \n",
        "        x = self.fc(output)\n",
        "        \n",
        "        return x, state, attention_weights\n",
        "        \n",
        "    def initialize_hidden_state(self):\n",
        "        return tf.zeros((self.batch_sz, self.dec_units))"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8oGe0qnwHyA5"
      },
      "source": [
        "tf.keras.backend.clear_session()\n",
        "\n",
        "encoder = Encoder(vocab_inp_size+1, 300, units, BATCH_SIZE)\n",
        "decoder = Decoder(vocab_tar_size+1, embedding_dim, units, BATCH_SIZE)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hV6fzW6vQzXd"
      },
      "source": [
        "optimizer = tf.keras.optimizers.Adam()\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True,\n",
        "                                                            reduction='none')\n",
        "\n",
        "\n",
        "def loss_function(real, pred):\n",
        "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "  loss_ = loss_object(real, pred)\n",
        "\n",
        "  mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "  loss_ *= mask\n",
        "\n",
        "  return tf.reduce_mean(loss_)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xf-qboRWQ4nC"
      },
      "source": [
        "@tf.function\n",
        "def train_step(inp, targ, enc_hidden):\n",
        "  loss = 0\n",
        "\n",
        "  with tf.GradientTape() as tape:\n",
        "    enc_output, enc_hidden = encoder(inp, enc_hidden)\n",
        "    encoder.get_layer('embedding_layer_encoder').set_weights([embedding_matrix])\n",
        "    dec_hidden = enc_hidden\n",
        "\n",
        "    dec_input = tf.expand_dims([targ_lang.word_index['<start>']] * BATCH_SIZE, 1)\n",
        "\n",
        "    for t in range(1, targ.shape[1]):\n",
        "      predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
        "\n",
        "      loss += loss_function(targ[:, t], predictions)\n",
        "\n",
        "      dec_input = tf.expand_dims(targ[:, t], 1)\n",
        "\n",
        "  batch_loss = (loss / int(targ.shape[1]))\n",
        "\n",
        "  variables = encoder.trainable_variables + decoder.trainable_variables\n",
        "\n",
        "  gradients = tape.gradient(loss, variables)\n",
        "\n",
        "  optimizer.apply_gradients(zip(gradients, variables))\n",
        "\n",
        "  return batch_loss"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lNTA90Y5UfeG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d39d91e2-ffe4-4bb1-a73f-104cdabf61b8"
      },
      "source": [
        "EPOCHS = 25\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "  start = time.time()\n",
        "\n",
        "  enc_hidden = encoder.initialize_hidden_state()\n",
        "  total_loss = 0\n",
        "\n",
        "  for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
        "    batch_loss = train_step(inp, targ, enc_hidden)\n",
        "    total_loss += batch_loss\n",
        "\n",
        "    if batch % 100 == 0:\n",
        "      print(f'Epoch {epoch+1} Batch {batch} Loss {batch_loss.numpy():.4f}')\n",
        "\n",
        "  print(f'Epoch {epoch+1} Loss {total_loss/steps_per_epoch:.4f}')\n",
        "  print(f'Time taken for 1 epoch {time.time()-start:.2f} sec\\n')"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 Batch 0 Loss 4.5265\n",
            "Epoch 1 Batch 100 Loss 4.7038\n",
            "Epoch 1 Batch 200 Loss 4.1336\n",
            "Epoch 1 Loss 4.4060\n",
            "Time taken for 1 epoch 49.53 sec\n",
            "\n",
            "Epoch 2 Batch 0 Loss 4.2796\n",
            "Epoch 2 Batch 100 Loss 4.5317\n",
            "Epoch 2 Batch 200 Loss 3.3027\n",
            "Epoch 2 Loss 4.0758\n",
            "Time taken for 1 epoch 27.89 sec\n",
            "\n",
            "Epoch 3 Batch 0 Loss 4.2790\n",
            "Epoch 3 Batch 100 Loss 3.2386\n",
            "Epoch 3 Batch 200 Loss 4.0803\n",
            "Epoch 3 Loss 3.8952\n",
            "Time taken for 1 epoch 27.90 sec\n",
            "\n",
            "Epoch 4 Batch 0 Loss 3.6541\n",
            "Epoch 4 Batch 100 Loss 3.5791\n",
            "Epoch 4 Batch 200 Loss 4.0321\n",
            "Epoch 4 Loss 3.7250\n",
            "Time taken for 1 epoch 27.92 sec\n",
            "\n",
            "Epoch 5 Batch 0 Loss 2.8685\n",
            "Epoch 5 Batch 100 Loss 4.3204\n",
            "Epoch 5 Batch 200 Loss 3.0883\n",
            "Epoch 5 Loss 3.5277\n",
            "Time taken for 1 epoch 27.81 sec\n",
            "\n",
            "Epoch 6 Batch 0 Loss 2.6236\n",
            "Epoch 6 Batch 100 Loss 3.3322\n",
            "Epoch 6 Batch 200 Loss 3.0510\n",
            "Epoch 6 Loss 3.2344\n",
            "Time taken for 1 epoch 27.82 sec\n",
            "\n",
            "Epoch 7 Batch 0 Loss 3.2872\n",
            "Epoch 7 Batch 100 Loss 2.8411\n",
            "Epoch 7 Batch 200 Loss 2.4500\n",
            "Epoch 7 Loss 2.7985\n",
            "Time taken for 1 epoch 27.96 sec\n",
            "\n",
            "Epoch 8 Batch 0 Loss 2.5121\n",
            "Epoch 8 Batch 100 Loss 1.8845\n",
            "Epoch 8 Batch 200 Loss 2.8410\n",
            "Epoch 8 Loss 2.1986\n",
            "Time taken for 1 epoch 27.99 sec\n",
            "\n",
            "Epoch 9 Batch 0 Loss 1.5979\n",
            "Epoch 9 Batch 100 Loss 1.6445\n",
            "Epoch 9 Batch 200 Loss 1.5257\n",
            "Epoch 9 Loss 1.5687\n",
            "Time taken for 1 epoch 27.97 sec\n",
            "\n",
            "Epoch 10 Batch 0 Loss 0.9585\n",
            "Epoch 10 Batch 100 Loss 1.2016\n",
            "Epoch 10 Batch 200 Loss 0.9834\n",
            "Epoch 10 Loss 1.1433\n",
            "Time taken for 1 epoch 28.03 sec\n",
            "\n",
            "Epoch 11 Batch 0 Loss 0.8802\n",
            "Epoch 11 Batch 100 Loss 1.0024\n",
            "Epoch 11 Batch 200 Loss 0.7817\n",
            "Epoch 11 Loss 0.9042\n",
            "Time taken for 1 epoch 27.96 sec\n",
            "\n",
            "Epoch 12 Batch 0 Loss 0.5212\n",
            "Epoch 12 Batch 100 Loss 0.8071\n",
            "Epoch 12 Batch 200 Loss 0.7295\n",
            "Epoch 12 Loss 0.7094\n",
            "Time taken for 1 epoch 28.16 sec\n",
            "\n",
            "Epoch 13 Batch 0 Loss 0.4448\n",
            "Epoch 13 Batch 100 Loss 0.6734\n",
            "Epoch 13 Batch 200 Loss 1.0378\n",
            "Epoch 13 Loss 0.5496\n",
            "Time taken for 1 epoch 27.98 sec\n",
            "\n",
            "Epoch 14 Batch 0 Loss 0.4588\n",
            "Epoch 14 Batch 100 Loss 0.4038\n",
            "Epoch 14 Batch 200 Loss 0.5322\n",
            "Epoch 14 Loss 0.4138\n",
            "Time taken for 1 epoch 27.93 sec\n",
            "\n",
            "Epoch 15 Batch 0 Loss 0.2499\n",
            "Epoch 15 Batch 100 Loss 0.3831\n",
            "Epoch 15 Batch 200 Loss 0.4452\n",
            "Epoch 15 Loss 0.3169\n",
            "Time taken for 1 epoch 27.77 sec\n",
            "\n",
            "Epoch 16 Batch 0 Loss 0.3147\n",
            "Epoch 16 Batch 100 Loss 0.2634\n",
            "Epoch 16 Batch 200 Loss 0.1657\n",
            "Epoch 16 Loss 0.2449\n",
            "Time taken for 1 epoch 27.81 sec\n",
            "\n",
            "Epoch 17 Batch 0 Loss 0.2091\n",
            "Epoch 17 Batch 100 Loss 0.1378\n",
            "Epoch 17 Batch 200 Loss 0.1296\n",
            "Epoch 17 Loss 0.1917\n",
            "Time taken for 1 epoch 27.90 sec\n",
            "\n",
            "Epoch 18 Batch 0 Loss 0.1765\n",
            "Epoch 18 Batch 100 Loss 0.0859\n",
            "Epoch 18 Batch 200 Loss 0.0818\n",
            "Epoch 18 Loss 0.1522\n",
            "Time taken for 1 epoch 27.89 sec\n",
            "\n",
            "Epoch 19 Batch 0 Loss 0.0765\n",
            "Epoch 19 Batch 100 Loss 0.0851\n",
            "Epoch 19 Batch 200 Loss 0.0849\n",
            "Epoch 19 Loss 0.1227\n",
            "Time taken for 1 epoch 27.90 sec\n",
            "\n",
            "Epoch 20 Batch 0 Loss 0.0780\n",
            "Epoch 20 Batch 100 Loss 0.1224\n",
            "Epoch 20 Batch 200 Loss 0.1207\n",
            "Epoch 20 Loss 0.1031\n",
            "Time taken for 1 epoch 27.88 sec\n",
            "\n",
            "Epoch 21 Batch 0 Loss 0.1196\n",
            "Epoch 21 Batch 100 Loss 0.1429\n",
            "Epoch 21 Batch 200 Loss 0.1823\n",
            "Epoch 21 Loss 0.0873\n",
            "Time taken for 1 epoch 27.83 sec\n",
            "\n",
            "Epoch 22 Batch 0 Loss 0.0402\n",
            "Epoch 22 Batch 100 Loss 0.0332\n",
            "Epoch 22 Batch 200 Loss 0.0570\n",
            "Epoch 22 Loss 0.0770\n",
            "Time taken for 1 epoch 27.93 sec\n",
            "\n",
            "Epoch 23 Batch 0 Loss 0.0732\n",
            "Epoch 23 Batch 100 Loss 0.0786\n",
            "Epoch 23 Batch 200 Loss 0.0337\n",
            "Epoch 23 Loss 0.0673\n",
            "Time taken for 1 epoch 27.99 sec\n",
            "\n",
            "Epoch 24 Batch 0 Loss 0.0141\n",
            "Epoch 24 Batch 100 Loss 0.0654\n",
            "Epoch 24 Batch 200 Loss 0.0354\n",
            "Epoch 24 Loss 0.0660\n",
            "Time taken for 1 epoch 27.79 sec\n",
            "\n",
            "Epoch 25 Batch 0 Loss 0.1295\n",
            "Epoch 25 Batch 100 Loss 0.0737\n",
            "Epoch 25 Batch 200 Loss 0.0206\n",
            "Epoch 25 Loss 0.0621\n",
            "Time taken for 1 epoch 27.76 sec\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o0sehhJFjZhE"
      },
      "source": [
        "def evaluate(sentence):\n",
        "  attention_plot = np.zeros((max_length_targ, max_length_inp))\n",
        "\n",
        "  sentence = preprocess(sentence)\n",
        "\n",
        "  inputs = [inp_lang.word_index[i] for i in sentence.split(' ')]\n",
        "  inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],maxlen=20, padding='post')\n",
        "  inputs = tf.convert_to_tensor(inputs)\n",
        "\n",
        "  result = ''\n",
        "\n",
        "  hidden = [tf.zeros((1, units))]\n",
        "  enc_out, enc_hidden = encoder(inputs, hidden)\n",
        "\n",
        "  dec_hidden = enc_hidden\n",
        "  dec_input = tf.expand_dims([targ_lang.word_index['<start>']], 0)\n",
        "\n",
        "  for t in range(max_length_targ):\n",
        "    predictions, dec_hidden, attention_weights = decoder(dec_input,\n",
        "                                                         dec_hidden,\n",
        "                                                         enc_out)\n",
        "    # storing the attention weights to plot later on\n",
        "    attention_weights = tf.reshape(attention_weights, (-1, ))\n",
        "    attention_plot[t] = attention_weights.numpy()\n",
        "    predicted_id = tf.argmax(predictions[0]).numpy()\n",
        "\n",
        "    result += targ_lang.index_word[predicted_id] + ' '\n",
        "\n",
        "    if targ_lang.index_word[predicted_id] == '<end>':\n",
        "      return result,attention_plot\n",
        "\n",
        "    # the predicted ID is fed back into the model\n",
        "    dec_input = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "  return result,attention_plot"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z9pfZPH2Rl2o",
        "outputId": "8ea45e08-9375-4091-da9c-8f9f268e0bbe"
      },
      "source": [
        "input_sentence= 'please ensure that you use the appropriate form '\n",
        "print('Input sentence in english : ',input_sentence)\n",
        "predicted_output,attention_plot=evaluate(input_sentence)\n",
        "print('Predicted sentence in telugu : ',predicted_output)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input sentence in english :  please ensure that you use the appropriate form \n",
            "Predicted sentence in telugu :  దయచేసి మీరు తగిన ఫారమ్‌ను ఉపయోగిస్తున్నారని నిర్ధారించుకోండి <end> \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4z2NmL-vTCDr",
        "outputId": "19fd986b-39bd-454d-a831-8de46077c18e"
      },
      "source": [
        "input_sentence='and do something with it to change the world '\n",
        "print('Input sentence in english : ',input_sentence)\n",
        "predicted_output,attention_plot=evaluate(input_sentence)\n",
        "print('Predicted sentence in telugu : ',predicted_output)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input sentence in english :  and do something with it to change the world \n",
            "Predicted sentence in telugu :  మరియు ప్రపంచాన్ని మార్చడానికి దానితో ఏదైనా చేయండి <end> \n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}